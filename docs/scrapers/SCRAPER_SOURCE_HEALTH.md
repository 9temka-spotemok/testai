# –°–∏—Å—Ç–µ–º–∞ –∑–¥–æ—Ä–æ–≤—å—è –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ (Source Health Service)

## üìã –û–±–∑–æ—Ä

`SourceHealthService` –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –Ω–æ–≤–æ—Å—Ç–µ–π –∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ—Ç–∫–ª—é—á–∞–µ—Ç –Ω–µ—Ä–∞–±–æ—Ç–∞—é—â–∏–µ URL, —á—Ç–æ–±—ã –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—Ç–∏—Ç—å –Ω–µ–Ω—É–∂–Ω—ã–µ HTTP-–∑–∞–ø—Ä–æ—Å—ã –∏ —É–ª—É—á—à–∏—Ç—å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å scraper'–∞.

## üéØ –¶–µ–ª—å

- **–°–æ–∫—Ä–∞—â–µ–Ω–∏–µ HTTP-–∑–∞–ø—Ä–æ—Å–æ–≤ –Ω–∞ 60-80%** –∑–∞ —Å—á—ë—Ç –∏—Å–∫–ª—é—á–µ–Ω–∏—è –Ω–µ—Ä–∞–±–æ—Ç–∞—é—â–∏—Ö URL
- **–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ—Ç–∫–ª—é—á–µ–Ω–∏–µ** URL, –∫–æ—Ç–æ—Ä—ã–µ –≤–æ–∑–≤—Ä–∞—â–∞—é—Ç 404/410 –∏–ª–∏ –ø—É—Å—Ç—ã–µ –æ—Ç–≤–µ—Ç—ã
- **–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ** URL, –∫–æ—Ç–æ—Ä—ã–µ —Å–Ω–æ–≤–∞ –Ω–∞—á–∏–Ω–∞—é—Ç —Ä–∞–±–æ—Ç–∞—Ç—å

## üîß –ö–∞–∫ —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç

### 1. –•—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö

–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∑–¥–æ—Ä–æ–≤—å–µ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ —Ö—Ä–∞–Ω–∏—Ç—Å—è –≤ `SourceProfile.metadata_json['dead_urls']`:

```json
{
  "normalized_url": {
    "status": "disabled" | "recovering" | "healthy",
    "fail_count": 5,
    "last_error": "404 Not Found" | "Empty response",
    "disabled_until": "2025-01-20T12:00:00Z" | null,
    "permanent": true | false,
    "last_success": "2025-01-15T10:00:00Z"
  }
}
```

### 2. –õ–æ–≥–∏–∫–∞ –æ—Ç–∫–ª—é—á–µ–Ω–∏—è

#### –ü–æ—Å—Ç–æ—è–Ω–Ω—ã–µ –æ—à–∏–±–∫–∏ (404/410)
- **–ü–æ—Ä–æ–≥:** 5 –Ω–µ—É–¥–∞—á–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫ –ø–æ–¥—Ä—è–¥
- **–î–µ–π—Å—Ç–≤–∏–µ:** URL –æ—Ç–∫–ª—é—á–∞–µ—Ç—Å—è **–Ω–∞–≤—Å–µ–≥–¥–∞** (`permanent: true`, `disabled_until: null`)
- **–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ:** –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏, –µ—Å–ª–∏ URL —Å–Ω–æ–≤–∞ –Ω–∞—á–∏–Ω–∞–µ—Ç –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç

#### –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã (–ø—É—Å—Ç—ã–µ –æ—Ç–≤–µ—Ç—ã)
- **–ü–æ—Ä–æ–≥:** 5 –Ω–µ—É–¥–∞—á–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫ –ø–æ–¥—Ä—è–¥
- **–î–µ–π—Å—Ç–≤–∏–µ:** URL –æ—Ç–∫–ª—é—á–∞–µ—Ç—Å—è **–≤—Ä–µ–º–µ–Ω–Ω–æ** –Ω–∞ 24 —á–∞—Å–∞ (`permanent: false`, `disabled_until: <–¥–∞—Ç–∞>`)
- **–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ:** –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —á–µ—Ä–µ–∑ 24 —á–∞—Å–∞ –∏–ª–∏ –ø—Ä–∏ —É—Å–ø–µ—à–Ω–æ–º –æ—Ç–≤–µ—Ç–µ

### 3. –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è URL

–í—Å–µ URL –Ω–æ—Ä–º–∞–ª–∏–∑—É—é—Ç—Å—è –ø–µ—Ä–µ–¥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º:
- –£–±–∏—Ä–∞–µ—Ç—Å—è trailing slash (`/blog` –∏ `/blog/` ‚Üí –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ)
- –î–æ–º–µ–Ω –ø—Ä–∏–≤–æ–¥–∏—Ç—Å—è –∫ lowercase
- –£–±–∏—Ä–∞—é—Ç—Å—è query params –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è

## üìä API

### `get_dead_urls(company_id: UUID) -> Set[str]`

–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–Ω–æ–∂–µ—Å—Ç–≤–æ –æ—Ç–∫–ª—é—á–µ–Ω–Ω—ã—Ö URL –¥–ª—è –∫–æ–º–ø–∞–Ω–∏–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω–æ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å –ø—Ä–∏ scraping.

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:**
```python
from app.domains.news.services.source_health_service import SourceHealthService

async with AsyncSessionLocal() as db:
    health_service = SourceHealthService(db)
    dead_urls = await health_service.get_dead_urls(company_id)
    # dead_urls = {"https://example.com/blog", "https://example.com/news"}
```

### `record_result(...)`

–ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–ø—ã—Ç–∫–∏ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–∞.

**–ü–∞—Ä–∞–º–µ—Ç—Ä—ã:**
- `company_id`: UUID –∫–æ–º–ø–∞–Ω–∏–∏
- `source_url`: URL –∏—Å—Ç–æ—á–Ω–∏–∫–∞ (–±—É–¥–µ—Ç –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω)
- `success`: –£—Å–ø–µ—à–Ω–æ—Å—Ç—å –∑–∞–ø—Ä–æ—Å–∞ (bool)
- `status`: HTTP —Å—Ç–∞—Ç—É—Å –∫–æ–¥ (int)
- `items_count`: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π (int)
- `source_type`: –¢–∏–ø –∏—Å—Ç–æ—á–Ω–∏–∫–∞ (SourceType, –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:**
```python
await health_service.record_result(
    company_id=company_id,
    source_url="https://example.com/blog",
    success=False,
    status=404,
    items_count=0,
    source_type=SourceType.BLOG,
)
```

### `should_skip_url(company_id: UUID, source_url: str) -> bool`

–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –Ω—É–∂–Ω–æ –ª–∏ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å URL.

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:**
```python
if await health_service.should_skip_url(company_id, url):
    logger.info(f"Skipping disabled URL: {url}")
    continue
```

## üîç –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞

### –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ç–∫–ª—é—á–µ–Ω–Ω—ã—Ö URL –¥–ª—è –∫–æ–º–ø–∞–Ω–∏–∏

```sql
SELECT 
    company_id,
    source_type,
    metadata_json->'dead_urls' as dead_urls
FROM source_profiles
WHERE company_id = 'YOUR_COMPANY_ID'::uuid
  AND metadata_json->'dead_urls' IS NOT NULL;
```

### –ü–æ–¥—Å—á—ë—Ç –æ—Ç–∫–ª—é—á–µ–Ω–Ω—ã—Ö URL

```sql
SELECT 
    company_id,
    source_type,
    jsonb_object_keys(metadata_json->'dead_urls') as disabled_url
FROM source_profiles
WHERE metadata_json->'dead_urls' IS NOT NULL
  AND jsonb_typeof(metadata_json->'dead_urls') = 'object';
```

### –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ URL

```sql
SELECT 
    company_id,
    source_type,
    metadata_json->'dead_urls'->'https://example.com/blog' as url_status
FROM source_profiles
WHERE metadata_json->'dead_urls'->'https://example.com/blog' IS NOT NULL;
```

### –ü–æ–∏—Å–∫ URL —Å –ø–æ—Å—Ç–æ—è–Ω–Ω—ã–º –æ—Ç–∫–ª—é—á–µ–Ω–∏–µ–º

```sql
SELECT 
    company_id,
    source_type,
    key as disabled_url,
    value->>'status' as status,
    value->>'permanent' as permanent,
    value->>'fail_count' as fail_count
FROM source_profiles,
     jsonb_each(metadata_json->'dead_urls')
WHERE value->>'status' = 'disabled'
  AND (value->>'permanent')::boolean = true;
```

## üîÑ –ü–µ—Ä–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏—Å—Ç–æ—á–Ω–∏–∫–∞

–ï—Å–ª–∏ URL –±—ã–ª –æ—Ç–∫–ª—é—á–µ–Ω –ø–æ –æ—à–∏–±–∫–µ –∏–ª–∏ –∏—Å—Ç–æ—á–Ω–∏–∫ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏–ª—Å—è, –º–æ–∂–Ω–æ –ø–µ—Ä–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å:

### –í–∞—Ä–∏–∞–Ω—Ç 1: –£–¥–∞–ª–∏—Ç—å –∑–∞–ø–∏—Å—å –≤—Ä—É—á–Ω—É—é

```sql
UPDATE source_profiles
SET metadata_json = jsonb_set(
    metadata_json,
    '{dead_urls}',
    (metadata_json->'dead_urls') - 'https://example.com/blog'
)
WHERE company_id = 'YOUR_COMPANY_ID'::uuid
  AND metadata_json->'dead_urls'->'https://example.com/blog' IS NOT NULL;
```

### –í–∞—Ä–∏–∞–Ω—Ç 2: –ó–∞–ø—É—Å—Ç–∏—Ç—å –ø–µ—Ä–≤–∏—á–Ω–æ–µ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ

```python
from app.tasks.scraping import scan_company_sources_initial

# –ó–∞–ø—É—Å—Ç–∏—Ç—å –∑–∞–¥–∞—á—É –¥–ª—è –∫–æ–º–ø–∞–Ω–∏–∏
scan_company_sources_initial.delay(str(company_id))
```

–≠—Ç–∞ –∑–∞–¥–∞—á–∞ –ø—Ä–æ–≤–µ—Ä–∏—Ç –≤—Å–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ URL –∏ –æ–±–Ω–æ–≤–∏—Ç —Å—Ç–∞—Ç—É—Å—ã –≤ `SourceHealthService`.

## üìà –ú–µ—Ç—Ä–∏–∫–∏

–°–∏—Å—Ç–µ–º–∞ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –≤ Prometheus:

- `scraper_dead_urls_count{company_id="..."}` ‚Äî –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∫–ª—é—á–µ–Ω–Ω—ã—Ö URL –¥–ª—è –∫–æ–º–ø–∞–Ω–∏–∏ (gauge)
- `scraper_requests_total{status="404", source_type="blog"}` ‚Äî –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø—Ä–æ—Å–æ–≤ –ø–æ —Å—Ç–∞—Ç—É—Å—É (counter)
- `scraper_duplicate_requests_total{source_type="blog"}` ‚Äî –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â—ë–Ω–Ω—ã—Ö –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ (counter)

## üöÄ –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è

### –í scraper'–µ

`UniversalBlogScraper` –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç `SourceHealthService`:

```python
# –ü—Ä–∏ scraping –∫–æ–º–ø–∞–Ω–∏–∏
skip_urls = await health_service.get_dead_urls(company.id)
items = await scraper.scrape_company_blog(
    company_name=company.name,
    website=company.website,
    skip_urls=skip_urls,  # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–æ–ø—É—Å–∫–∞—é—Ç—Å—è –æ—Ç–∫–ª—é—á–µ–Ω–Ω—ã–µ URL
    company_id=company.id,
    health_service=health_service,
)

# –ü–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
await health_service.record_result(
    company_id=company.id,
    source_url=url,
    success=success,
    status=status_code,
    items_count=items_count,
    source_type=SourceType.BLOG,
)
```

### –ü–µ—Ä–≤–∏—á–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è

–ü—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –Ω–æ–≤–æ–π –∫–æ–º–ø–∞–Ω–∏–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –∑–∞–¥–∞—á–∞ `scan_company_sources_initial`, –∫–æ—Ç–æ—Ä–∞—è:
1. –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤—Å–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ URL –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
2. –ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ `SourceHealthService`
3. –û—Ç–∫–ª—é—á–∞–µ—Ç –Ω–µ—Ä–∞–±–æ—Ç–∞—é—â–∏–µ URL —Å—Ä–∞–∑—É

## ‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏

–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–∂–Ω–æ –∏–∑–º–µ–Ω–∏—Ç—å –≤ `SourceHealthService`:

```python
FAIL_THRESHOLD = 5  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ—É–¥–∞—á–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫ –ø–µ—Ä–µ–¥ –æ—Ç–∫–ª—é—á–µ–Ω–∏–µ–º
DISABLE_DURATION_HOURS = 24  # –ß–∞—Å—ã –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –æ—Ç–∫–ª—é—á–µ–Ω–∏—è (—Ç–æ–ª—å–∫–æ –¥–ª—è –ø—É—Å—Ç—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤)
```

## üîç –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ

–°–∏—Å—Ç–µ–º–∞ –ª–æ–≥–∏—Ä—É–µ—Ç –≤–∞–∂–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è:

- `URL {url} permanently disabled (404/410) for company {company_id}` ‚Äî –ø–æ—Å—Ç–æ—è–Ω–Ω–æ–µ –æ—Ç–∫–ª—é—á–µ–Ω–∏–µ
- `URL {url} temporarily disabled (empty response) for company {company_id}` ‚Äî –≤—Ä–µ–º–µ–Ω–Ω–æ–µ –æ—Ç–∫–ª—é—á–µ–Ω–∏–µ
- `URL {url} succeeded, resetting fail count for company {company_id}` ‚Äî —É—Å–ø–µ—à–Ω–æ–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ

## üìù –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

### –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –∫–æ–º–ø–∞–Ω–∏–∏

```python
from app.domains.news.services.source_health_service import SourceHealthService
from app.core.database import AsyncSessionLocal

async with AsyncSessionLocal() as db:
    health_service = SourceHealthService(db)
    dead_urls = await health_service.get_dead_urls(company_id)
    
    print(f"–û—Ç–∫–ª—é—á–µ–Ω–æ URL: {len(dead_urls)}")
    for url in dead_urls:
        print(f"  - {url}")
```

### –†—É—á–Ω–∞—è –∑–∞–ø–∏—Å—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞

```python
await health_service.record_result(
    company_id=company_id,
    source_url="https://example.com/blog",
    success=True,
    status=200,
    items_count=5,
    source_type=SourceType.BLOG,
)
```

## üêõ –†–µ—à–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º

### URL –Ω–µ –æ—Ç–∫–ª—é—á–∞–µ—Ç—Å—è

1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ `record_result` –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
2. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ `fail_count` –¥–æ—Å—Ç–∏–≥–∞–µ—Ç –ø–æ—Ä–æ–≥–∞ (5)
3. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –æ—à–∏–±–æ–∫

### URL –æ—Ç–∫–ª—é—á—ë–Ω, –Ω–æ –¥–æ–ª–∂–µ–Ω —Ä–∞–±–æ—Ç–∞—Ç—å

1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å—Ç–∞—Ç—É—Å –≤ –ë–î (—Å–º. SQL –∑–∞–ø—Ä–æ—Å—ã –≤—ã—à–µ)
2. –£–¥–∞–ª–∏—Ç–µ –∑–∞–ø–∏—Å—å –≤—Ä—É—á–Ω—É—é –∏–ª–∏ –∑–∞–ø—É—Å—Ç–∏—Ç–µ –ø–µ—Ä–≤–∏—á–Ω–æ–µ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ
3. –ü—Ä–∏ —Å–ª–µ–¥—É—é—â–µ–º scraping URL –±—É–¥–µ—Ç –ø—Ä–æ–≤–µ—Ä–µ–Ω —Å–Ω–æ–≤–∞

### –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –æ—Ç–∫–ª—é—á—ë–Ω–Ω—ã—Ö URL

1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –º–µ—Ç—Ä–∏–∫—É `scraper_dead_urls_count`
2. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –ø—Ä–æ–±–ª–µ–º —Å —Å–µ—Ç—å—é
3. –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å —É–≤–µ–ª–∏—á–µ–Ω–∏—è `FAIL_THRESHOLD`

---

**–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ:** 2025-01-19  
**–§–∞–π–ª:** `backend/app/domains/news/services/source_health_service.py`

