# Phase 0 — Baseline Metrics Capture (12 Nov 2025)

**Ответственный:** GPT-5 Codex (backend)  
**Статус:** В процессе — требуется выполнить замеры на рабочем окружении

---

## 1. Подготовка окружения
- Запустите `docker-compose up -d postgres redis backend celery-worker celery-beat`.
- Убедитесь, что Prometheus/OTel метрики доступны:
  - Prometheus экспортёр: `http://localhost:9464/metrics`
  - OpenTelemetry (опционально): настройте `OTEL_METRICS_EXPORTER=prometheus` и `CELERY_OTEL_ENABLED=true`.
- Celery логи должны отображать включение метрик: `Started Celery Prometheus exporter on 0.0.0.0:9464`.

## 2. API Performance (pending measurement)
| Endpoint | Метод | План замера | Команда | Статус |
|----------|-------|-------------|---------|--------|
| `/api/v1/news` | GET | 200 rps / 60s (k6) | `BASE_URL=http://localhost:8000 AUTH_TOKEN=$TOKEN k6 run tests/performance/api_news.js` | pending |
| `/api/v1/companies/scan` | POST | 25 rps / 30s (hey) | `hey -n 750 -c 25 -m POST -H "Authorization: Bearer $TOKEN" -T "application/json" -d @tests/performance/payloads/company-scan.json http://localhost:8000/api/v1/companies/scan` | pending |
| `/api/v2/analytics/companies/{id}/impact/latest` | GET | 100 rps / 60s (k6) | `BASE_URL=http://localhost:8000 AUTH_TOKEN=$TOKEN COMPANY_ID=$COMPANY k6 run tests/performance/api_analytics_impact.js` | pending |

> После прогонов внесите реальные показатели в `docs/REFACTORING/metrics/phase0_baseline_metrics.md`.

**Подсказки:**
- Файлы сценариев находятся в `backend/tests/performance/`. Настройте интенсивность через переменные `VUS`, `DURATION`, `NEWS_LIMIT`, `PERIOD`.
- Для `companies/scan` подготовьте рабочий payload на основе шаблона `backend/tests/performance/payloads/company-scan.template.json` (скопируйте в `company-scan.json` и замените значения на реальные домены).
- Токен авторизации можно получить через `/api/v1/auth/login` и сохранить в переменной окружения `TOKEN`.

## 3. Celery / Background Jobs (instrumented)
- Новые счётчики доступны через Prometheus:
  - `shot_news_celery_task_total{task_name=...,status=success|failure|duplicate}`
  - `shot_news_celery_task_duration_seconds_bucket{task_name=...,queue=...}`
  - `shot_news_celery_task_duplicates_total`
- Дедупликация задач:
  - Для аналитических задач используется ключ `analytics:<scope>:...`. При повторной постановке возвращается payload `{"status": "duplicate", ...}` без выполнения.
- Smoke-проверка:
  ```bash
  curl http://localhost:9464/metrics | grep celery_task_total
  ```
- Для ручного запуска и мониторинга:
  ```bash
  poetry run celery -A app.celery_app call app.tasks.analytics.recompute_all_analytics --kwargs '{"period": "daily", "lookback": 30}'
  ```

## 4. Frontend Web Vitals (pending measurement)
| Сценарий | Инструмент | План замера | Статус |
|----------|------------|-------------|--------|
| Competitor Analysis → Export | Lighthouse CI (desktop & mobile) | `npm run lighthouse:competitor-analysis` | pending |
| Digest Settings → Save | Playwright trace | `npm run test:e2e -- --grep "@metrics-digest"` | pending |
| Dashboard Landing | Lighthouse (mobile) | `npm run lighthouse:dashboard` | pending |

## 5. Инфраструктура / Ресурсы
- Зафиксировать версии: `docker-compose exec backend poetry run python -c "import platform; print(platform.python_version())"`, `docker-compose exec redis redis-server --version`.
- Снять `docker stats backend celery-worker redis postgres > docs/REFACTORING/metrics/raw/docker-stats.log`.
- Размер БД: `docker-compose exec postgres psql -U shot_news -c "\l+"`.

## 6. Контрольный список
- [ ] Выполнить нагрузочные профили (раздел 2) и заполнить таблицу шаблона.
- [ ] Собрать метрики Celery и убедиться в появлении счётчиков в Prometheus.
- [ ] Снять Lighthouse/Playwright метрики и приложить отчёты.
- [ ] Загрузить артефакты в `docs/REFACTORING/metrics/raw/` и обновить README/SETUP ссылками.

---

**Следующие шаги:** после заполнения всех пунктов обновить `docs/REFACTORING/metrics/phase0_baseline_metrics.md` и приложить ссылки на артефакты в README (`Observability` раздел).

